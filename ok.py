# -*- coding: utf-8 -*-
"""ok.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1rz3NZQHyVNa00G8myho7Nd_O0o8_3ohG
"""

import streamlit as st
import os
import sys
import tempfile
import shutil
import zipfile
import subprocess
from pathlib import Path
from PIL import Image
import io
import time

st.set_page_config(page_title="YOLO Train/Test/Detect (Integrated)", layout="wide")

# ---------- Helper utilities ----------
def install_package(pkg):
    try:
        __import__(pkg)
        return True
    except Exception:
        st.info(f"Installing {pkg} ...")
        subprocess.check_call([sys.executable, "-m", "pip", "install", pkg])
        try:
            __import__(pkg)
            return True
        except Exception as e:
            st.error(f"Failed to install {pkg}: {e}")
            return False

def download_file_from_gdrive(file_id, dest_path):
    """
    Download a single file from Google Drive using gdown (for public files).
    Returns True on success.
    """
    if not install_package("gdown"):
        return False
    import gdown
    url = f"https://drive.google.com/uc?export=download&id={file_id}"
    try:
        gdown.download(url, dest_path, quiet=False)
        return os.path.exists(dest_path)
    except Exception as e:
        st.warning(f"gdown failed: {e}")
        return False

def extract_zip(zip_path, dest_dir):
    try:
        with zipfile.ZipFile(zip_path, "r") as zf:
            zf.extractall(dest_dir)
        return True
    except Exception as e:
        st.error(f"Failed to extract {zip_path}: {e}")
        return False

def find_best_pt(run_dir="."):
    # look into common ultralytics run directories for best.pt
    for root, dirs, files in os.walk(run_dir):
        if "best.pt" in files:
            return os.path.join(root, "best.pt")
    return None

# ---------- App UI ----------
st.title("ðŸ”§ YOLO Train / Test / Detect â€” Integrated Streamlit App")
st.write("Modes: train a model, test/validate, or run detection on uploaded images.")

col1, col2 = st.columns([2, 1])

with col1:
    mode = st.selectbox("Select mode", ["Train Model", "Test Model", "Run Detection"])

    st.markdown("### Google Drive / dataset links (optional)")
    st.write("You provided Drive links earlier â€” paste Drive IDs below to let the app try to auto-download.")
    gdrive_train_folder_id = st.text_input("Train folder ID (Drive)", value="1uq2LhlMk6Kwfh5Qq6Gy7aieQJ686DRKy")
    gdrive_test_folder_id  = st.text_input("Test folder ID (Drive)", value="1fTisZ5br7fPPlxc58lrvHSOOyHBXpDTq")
    gdrive_yaml_file_id    = st.text_input("data.yaml file ID (Drive)", value="1NWX2DtQqEfG4CRGczyqYvTkAcnkhE7aq")

    st.markdown("---")
    st.markdown("### Model config")
    default_model_name = st.text_input("Base model (ultralytics name or local .pt)", value="yolov12n.pt")
    epochs = st.number_input("Epochs", min_value=1, max_value=1000, value=50)
    imgsz = st.number_input("Image size (px)", min_value=128, max_value=2048, value=640)
    batch = st.number_input("Batch size", min_value=1, max_value=256, value=16)

    st.markdown("---")
    st.markdown("### Optional: Upload dataset zips (if Drive folder download not possible)")
    train_zip = st.file_uploader("Upload train dataset zip (optional)", type=["zip"])
    test_zip  = st.file_uploader("Upload test dataset zip (optional)", type=["zip"])
    st.markdown("If you upload zips, the app will extract them to a temporary folder and adjust the `data.yaml` accordingly.")

with col2:
    st.markdown("### Model weights")
    uploaded_pt = st.file_uploader("Upload a .pt model (optional) â€” this will be used for detection/testing if provided", type=["pt"])
    st.markdown("---")
    st.markdown("### Quick actions")
    run_button = st.button("Run selected mode")

# ---------- Prepare environment ----------
# Ensure ultralytics is installed
if not install_package("ultralytics"):
    st.error("Please ensure 'ultralytics' is available (app attempted to install it). Exiting.")
    st.stop()

# Import after install
from ultralytics import YOLO

# temporary workspace
workspace = Path(tempfile.mkdtemp(prefix="yolo_streamlit_"))
st.info(f"Workspace: `{workspace}` (temporary). Files will be placed here.")

# try to download data.yaml automatically
yaml_local_path = workspace / "data.yaml"
if gdrive_yaml_file_id:
    if not yaml_local_path.exists():
        try:
            st.info("Attempting to download data.yaml from Google Drive...")
            success = download_file_from_gdrive(gdrive_yaml_file_id, str(yaml_local_path))
            if success:
                st.success("Downloaded data.yaml")
            else:
                st.warning("Could not auto-download data.yaml. You may upload it manually below.")
        except Exception as e:
            st.warning(f"Error downloading data.yaml: {e}")

yaml_upload = st.file_uploader("Upload data.yaml (optional if not auto-downloaded)", type=["yaml", "yml"])
if yaml_upload is not None:
    yaml_local_path.write_bytes(yaml_upload.getbuffer())
    st.success("data.yaml uploaded to workspace.")

# If user uploaded zips, extract them
train_dir = workspace / "train"
test_dir = workspace / "test"
train_dir.mkdir(exist_ok=True)
test_dir.mkdir(exist_ok=True)

if train_zip is not None:
    train_zip_path = workspace / "train.zip"
    train_zip_path.write_bytes(train_zip.getbuffer())
    extract_zip(str(train_zip_path), str(train_dir))
    st.success("Extracted train zip.")

if test_zip is not None:
    test_zip_path = workspace / "test.zip"
    test_zip_path.write_bytes(test_zip.getbuffer())
    extract_zip(str(test_zip_path), str(test_dir))
    st.success("Extracted test zip.")

# If user uploaded a model .pt, save it
uploaded_pt_path = None
if uploaded_pt is not None:
    uploaded_pt_path = workspace / uploaded_pt.name
    uploaded_pt_path.write_bytes(uploaded_pt.getbuffer())
    st.success(f"Uploaded model saved to {uploaded_pt_path}")

# ---------- Main actions ----------
if run_button:
    st.write(f"Running mode: **{mode}**")
    if mode == "Train Model":
        # Check yaml exists or ask user to supply dataset paths
        if not yaml_local_path.exists():
            st.error("data.yaml not found. Please upload it or provide a valid Drive file ID for data.yaml.")
        else:
            st.info(f"Using data.yaml at {yaml_local_path}")
            model_name = default_model_name.strip()
            st.info(f"Using base model: {model_name}")
            try:
                # instantiate model (this will download the base weights if a hub name is used)
                model = YOLO(model_name)
            except Exception as e:
                st.error(f"Failed to load base model '{model_name}': {e}")
                st.stop()

            st.info("Starting training â€” logs will appear below. Training can take long (especially without GPU).")
            # Run training. Note: ultralytics prints progress to stdout, we will run directly.
            try:
                # set save directory inside workspace
                save_dir = os.path.join(workspace, "runs")
                # call train
                results = model.train(data=str(yaml_local_path), epochs=int(epochs), imgsz=int(imgsz),
                                      batch=int(batch), project=str(workspace), name="train_run", exist_ok=True)
                st.success("Training completed.")
                # try to locate best.pt
                best = find_best_pt(str(workspace))
                if best:
                    st.success(f"Found trained weights: {best}")
                else:
                    st.warning("Training finished but couldn't find best.pt automatically. Check the training output folder.")
            except Exception as e:
                st.error(f"Training failed: {e}")

    elif mode == "Test Model":
        # Determine which weights to use
        weights_to_use = None
        if uploaded_pt_path:
            weights_to_use = str(uploaded_pt_path)
            st.info(f"Using uploaded weights: {weights_to_use}")
        else:
            found = find_best_pt(str(workspace))
            if found:
                weights_to_use = found
                st.info(f"Using found weights: {weights_to_use}")
            else:
                # check local working dir
                local_best = find_best_pt(".")
                if local_best:
                    weights_to_use = local_best
                    st.info(f"Using best.pt from working dir: {weights_to_use}")
        if weights_to_use is None:
            st.error("No weights found. Upload a .pt or train first.")
        else:
            try:
                model = YOLO(weights_to_use)
                st.info("Running validation (model.val()) ...")
                metrics = model.val()
                st.write("Validation metrics (raw):")
                st.write(metrics)
                st.success("Validation finished.")
            except Exception as e:
                st.error(f"Validation failed: {e}")

    elif mode == "Run Detection":
        # Which weights to use?
        weights_to_use = None
        if uploaded_pt_path:
            weights_to_use = str(uploaded_pt_path)
        else:
            found = find_best_pt(str(workspace))
            if found:
                weights_to_use = found
            else:
                local_best = find_best_pt(".")
                if local_best:
                    weights_to_use = local_best

        if weights_to_use is None:
            st.warning("No trained weights found. You can either upload a .pt model or train one from the Train Model mode.")
            weights_choice = st.file_uploader("Upload a .pt model to use for detection", type=["pt"])
            if weights_choice is not None:
                weights_to_use = os.path.join(str(workspace), weights_choice.name)
                with open(weights_to_use, "wb") as f:
                    f.write(weights_choice.getbuffer())
                st.success("Uploaded .pt saved.")

        if weights_to_use is not None:
            st.info(f"Loading model: {weights_to_use}")
            try:
                model = YOLO(weights_to_use)
            except Exception as e:
                st.error(f"Failed to load model: {e}")
                st.stop()

            st.success("Model loaded â€” upload an image to run detection.")
            image_file = st.file_uploader("Upload an otoscopic image for detection", type=["png", "jpg", "jpeg"])
            conf = st.slider("Confidence threshold", 0.0, 1.0, 0.25, 0.01)
            if image_file is not None:
                img = Image.open(image_file).convert("RGB")
                st.image(img, caption="Input image", use_column_width=True)
                if st.button("Run inference on this image"):
                    # save temp
                    tmp_img_path = workspace / "input.jpg"
                    img.save(tmp_img_path)
                    st.info("Running model.predict ...")
                    try:
                        results = model.predict(source=str(tmp_img_path), conf=float(conf), verbose=False)
                        r = results[0]
                        # r.plot() returns numpy array
                        annotated = r.plot()
                        annotated_pil = Image.fromarray(annotated)
                        st.image(annotated_pil, caption="Annotated result", use_column_width=True)
                        # Optionally save
                        save_out = workspace / "last_result.jpg"
                        annotated_pil.save(save_out)
                        st.success(f"Result saved to {save_out}")
                        # Show raw boxes info if user wants
                        if st.checkbox("Show raw boxes / detection details"):
                            st.write(getattr(r, "boxes", "No boxes attribute"))
                    except Exception as e:
                        st.error(f"Detection failed: {e}")
        else:
            st.error("No weights provided or found.")

st.markdown("---")
st.caption("Note: workspace is temporary. Download any artifacts you need before closing the app.")

# ---------- Cleanup button ----------
if st.button("Remove workspace now"):
    try:
        shutil.rmtree(workspace)
        st.success("Workspace removed.")
    except Exception as e:
        st.error(f"Failed to remove workspace: {e}")